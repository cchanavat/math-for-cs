\section{Logic}

Mathematics is a language made of sentences. These sentences are written using the syntax and rules of logic. In this chapter, we learn the basics of logic's grammar, and how to make well formed sentences. Then, given a well formed sentence, we see a general procedure to see wether a given sentence how to see that it is true, that is, we will learn how to make proofs. 

\subsection{Connective}

We start with a few list of symbols, that constitute the basic alphabet of mathematics. It is primordial to know them, they are called \cemph{connectives}. We have

\begin{enumerate}
    \item The \cemph{and}, noted \( \land \). 
    \item The \cemph{or}, noted \( \lor \). 
    \item The \cemph{not}, noted \( \neg \). 
    \item The \cemph{implies}, noted \( \implies \). 
    \item The \cemph{equivalent}, noted \( \iff \). 
\end{enumerate}

As in any language, these symbols have meanings, that somewhat correspond to the intuition. To understand it, let us abbreviate with the letter \( C \), the sentence \textit{the cat is orange}, and with \( D \) the sentence \textit{the dog has three legs}. Then, we write
\begin{equation*}
    C \land D
\end{equation*}
to mean that both the cat is orange \cemph{and} the dog is sleeping. Thus, whenever we see the cat, it is orange, and whenever we see the dog, it has three leg. 

Next is the or. It is a little bit different than what we are used to in the English language. We write
\begin{equation*}
    C \lor D
\end{equation*}
to mean that the cat is orange, \cemph{or} the dog has three leg. This means that at least one of the three following statements is true:
\begin{enumerate}
    \item The cat is orange,
    \item The dog has three legs,
    \item The cat is orange, and the dog has three legs.
\end{enumerate}
In math, the or connective needs not to be exclusive. In \( C \lor D \), both \( C \) and \( D \) can be true at the same time. It means that after seeing the cat and the dog, we are guarantee that at least the cat will be orange, or the dog will have three legs, at least one of the two statements will be true. 

The next connective of interest is not. We write
\begin{equation*}
    \neg D
\end{equation*}
to mean that the dog has \cemph{not} three legs, that is whenever we will see the dog, it will have some number of legs and we are guarantee that this number is not three. It can be one, it can be four, it can be something else, but it will not be three.

\begin{cex}{}{and_not}
    Argue that \( \neg(C \land D) \) says the same thing as \( \neg C \lor \neg D \).
\end{cex}

We move on to equivalence. We write 
\begin{equation*}
    C \iff D
\end{equation*}
to mean that knowing that the cat is orange is the same thing as knowing that the dog has three legs. It means that if we go first to see the cat and conclude it is orange, then we do not need to go to the dog to see it has three leg. \textit{we already know it}. Conversely, if we go first see the dog, and it has three legs, then we are sure that the cat is orange. We also say \( C \) \cemph{if and only if} \( D \).

\begin{cex}{}{iff_sym}
    Argue that \( C \iff D \) says the same thing as \( D \iff C \).
\end{cex}

Finally, we have the implication. It is the most used of them all. We write
\begin{equation*}
    C \implies D
\end{equation*}
to mean that \cemph{if} the cat is orange, \cemph{then} the dog has three legs. It says that if we go see the cat and conclude it is orange, then we are guarantee that the dog will have three legs. However, and this is very important, if we do not see that the cat is orange, then we \textit{cannot} say anything at all about the dog, it might, or might not, have three legs. Unfortunately, the intuitive meaning of the implication does not really reflect well any construct in the English language. The implication is better understood as a function, \( C \implies D \) is a procedure that takes a proof that the cat is orange, and transforms it into a proof that the dog has three legs. Therefore, if the cat is not orange, we will never be able to call feed this procedure with a proof of orangeness of the cat, and therefore this procedure will not let us prove that the dog has three leg. However, there might perfectly well exists another procedure proving that the dog has three legs by other means, not involving the color of the cat.  

\begin{cex}{}{iff_double_implies}
    Argue that \( (C \implies D) \land (D \implies C) \) says the same thing as \( C \iff D \). Is \( C \implies D \) saying the same thing as \(  D \implies C \)?
\end{cex}

Notice that when we will do math later, we will freely use the symbol themselves, or their equivalent English terminology. In particular, we write "if \( X \) then \( Y \)" more often than "\( X \implies Y \)", but keep in mind that they are the same thing. We summarize these constructions with truth tables, you should refer to these when in doubt on what a sentence mean. Here is how to read it. The number \( 1 \) means True, the number \( 0 \) means False. In the table for \( \lor \), on a given row, a column gives a particular truth value to \( C \), to \( D \), and to the resulting \( C \lor D \). For instance, if \( C \) is true, \( D \) is false, we see that \( C \lor D \) is true.  
\begin{equation*}
    \begin{array}{| c | c |}
        \hline
        C & \neg C \\
        \hline
        0 & 1 \\
        \hline
        0 & 0 \\
        \hline
    \end{array},
    \begin{array}{| c | c | c |}
        \hline
        C & D & C \land D \\
        \hline
        0 & 0 & 0 \\
        \hline
        0 & 1 & 0 \\
        \hline
        1 & 0 & 0 \\
        \hline
        1 & 1 & 1 \\
        \hline
    \end{array},
    \begin{array}{| c | c | c |}
        \hline
        C & D & C \lor D \\
        \hline
        0 & 0 & 0 \\
        \hline
        0 & 1 & 1 \\
        \hline
        1 & 0 & 1 \\
        \hline
        1 & 1 & 1 \\
        \hline
    \end{array},
    \begin{array}{| c | c | c |}
        \hline
        C & D & C \iff D \\
        \hline
        0 & 0 & 1 \\
        \hline
        0 & 1 & 0 \\
        \hline
        1 & 0 & 0 \\
        \hline
        1 & 1 & 1 \\
        \hline
    \end{array},
    \begin{array}{| c | c | c |}
        \hline
        C & D & C \implies D \\
        \hline
        0 & 0 & 1 \\
        \hline
        0 & 1 & 1 \\
        \hline
        1 & 0 & 0 \\
        \hline
        1 & 1 & 1 \\
        \hline
    \end{array}
\end{equation*}


\subsection{Quantifiers}

So far, we cannot really say much. We need to introduce two new symbols:
\begin{equation*}
    \forall, \exists.
\end{equation*}
They will allow us to quantify, to say that all things in a big thing share the same property, or that there is some thing in a big thing that has a property. However, there is some subtleties that come with those symbols, we need to use free variables. Earlier, we said \( D \) means that the dog has three legs. There is no room in this formula, everything is fixed. Let us to do something, and replace "three" with the letter \( n \), that we declare to be an unspecified natural number. Now, we write 
\begin{equation*}
    D(n)
\end{equation*}  
to mean "the dog has \( n \) legs", for some number \( n \), that we deliberately \textit{not} specify. This \( n \) is called a free variable, it can potentially be any natural number, and it is good to think of it as being \textit{all} the natural number at the same time. Now, if we take a natural number, say \( 7 \), then we will write \( D(7) \) to specify the unknown number \( n \) with 7, and \( D(7) \) means that the dog has seven legs. Notice that the previous sentence \( D \) has now become \( D(3) \). 

Is the sentence \( D(n) \) true or false? It does not make sense to ask this question. We cannot ask for the truth value of a sentence with free variables, we first need to specify a behavior for our free variable, and this is done with the quantifier. We write
\begin{equation*}
    \exists n, D(n)
\end{equation*}
to mean that there \cemph{exists} at least a value of \( n \) (like 4, 9, or seven billion) such that the dog has \( n \) legs. For instance, we know \( \exists n, D(n) \) is true because when we will look at the dog, we will count its number of legs, and see that there is \( n = 4 \). We say that \( 4 \) is a \cemph{witness} of \( \exists n, D(n) \). 

Next, we write
\begin{equation*}
    \forall n, D(n)
\end{equation*}
to mean that \cemph{for all} choices of number \( n \), the dog will have precisely this number of legs. Here, this is quite absurd, because the dog has one and only one number of leg. But consider the following:
\begin{equation*}
    \forall n, (5 \leq n \implies \neg D(n)).
\end{equation*} 
It means that for all number \( n \), if the number \( n \) is greater or equal to 5, then the dog has not \( n \) legs. This feels more true, as we know indeed that the dog has four legs. 

\begin{cex}{}{write_sentences}
    Is \( \exists n, \neg D(n) \) true? Can you rewrite \( \neg \exists n, \neg D(n) \) as something with less symbols?
\end{cex}


\subsection{Practical sentences, and how to do proofs}

This was only the tip of the iceberg. Logic is a very powerful language that allows us to communicate with math. Ultimately, we want to do proofs. This section is a practical place that you are invited to read, and re-read every time you are confused with things. 

\subsubsection{What is a proof?}

What is a proof? A proof is a way to testify that a mathematical sentence is true. We saw in the previous part how to construct mathematical sentences, but we didn't see how to prove them.
\begin{cdef}{}{what_is_proof}
    A \cemph{proof} is a succession of mathematically sound steps. Whenever you write a proof, you always have a \cemph{bag of hypothesis}. This bag of hypothesis is a collection of mathematical sentences that you locally assume as true. The bag will grow during the proof (we will see how), and the goal of a proof is to reach a certain mathematical sentence (the conclusion) by mean of logical steps that combine the hypothesis in the bag. The bag is implicit, and is never explicitly described in textbooks. It consists of:
    \begin{enumerate}
        \item The statements that are always true (i.e. the theorem we already proved),
        \item The axioms that our objects of interest satisfy (for instance, if there is some \( r \in \bb Q \) in the proof, then by definition, we can say \( r = \frac p q \) with \( p, q \) integers).
        \item The local assumptions, that is, the things we assumed to be true for the sake of our proof, but that are not always true. What does it mean? We will understand it better when we will talk about implication, but for instance consider the statement "if \( n \) is even, then \( n + 1 \) is odd". Then to prove that, we will take some \( n \), and assume for the sake of the proof, that \( n \) is even. However, we are \textit{not} claiming that all \( n \)'s are even, we are only assuming that locally, for our precise needs, \( n \) is even. It is like when we write a function in programming language. For instance if we write the function:
        \begin{verbatim}
            float my_proof (int n) {
                ...
            }
        \end{verbatim} 
        then we do not say that there is always (outside of the scope of the function) some \verb|n| of type \verb|int|, we merely say that during the construction of the function \verb|my_proof|, we are allowed to use a variable of type \verb|int| (this correspondence is very deep, \href{https://en.wikipedia.org/wiki/Curry%E2%80%93Howard_correspondence}{functions and proofs are the same thing}). 
    \end{enumerate}
\end{cdef}
\cemph{Do not forget your hypothesis}, they are what you need to write your proofs. When you are stuck in a proof, first look if any of your local hypothesis are useful to move towards the goal. If you do not see anything relevant, look at the recent and related theorems we proved. Is there any that would significantly transform the \textit{state} of the proof into something more interesting to work with? Can the application of a theorem give new hypothesis that will be useful to move forwards?

\subsubsection{Constructing proofs}

Now that we know what a proof is supposed to do, we summarize here how to construct them. Say we want to prove a mathematical statement, then it is a formula written in the language of logic. This formula have a certain shape, and depending on its shape, we will apply certain proof techniques. Thus, we will see that math is in fact a very mechanical procedure. To do a proof, it suffices to pattern match with the following list. It is good to reflect on why those really prove what we want to prove, given what we saw in the previous chapter.

\begin{itemize}
    \item If you need to prove a statement of the form
        \begin{equation*}
           A \land B,
        \end{equation*}
        then you will do two proofs, first you will prove \( A \), then you will prove \( B \). For instance,
        \begin{equation*}
            4 \text{ is even } \land 7 \text{ is odd}.
        \end{equation*}
        \begin{proof}
            We have that \( 4 = 2 k \) with \( k = 2 \), thus is even. Next, \( 7 = 2k + 1 \) with \( k = 3 \), so is odd.
        \end{proof}

    \item If you need to prove a statement of the form
        \begin{equation*}
            \forall x \in X, P(x),
        \end{equation*}
        that is a statement that starts with a forall, then \cemph{your proof will begin by "let \( x \in X \)"}. That is, when a statement starts with forall, you should pick an element of the thing we quantify over, and keep this element in your pocket. It is yours now. When you say "let \( x \in X \)", then you have an \( x \), and this \( x \) belongs to \( X \), so it enjoys all the properties of a being in \( X \). Then, with this \( x \) in hand, we now prove \( P(x) \) (where the \( x \) in \( P(x) \) is that one \( x \) that we just picked in \( X \)). For instance,
        \begin{equation*}
            \forall x \in \{ t \in \bb R \mid t(t - 2) = 0\}, x + 1 \text{ is odd }. 
        \end{equation*}
        \begin{proof}
            Let \( x \in \{ t \in \bb R \mid t(t - 2) = 0\} \), then \( x^2(x - 2) = 0 \), so \( x = 0 \), or \( x = 2 \), that is \( x + 1 = 1 \) or \( x + 1 = 3 \), in both cases, \( x + 1 \) is odd.
        \end{proof}

    \item If you need to prove a statement of the form
        \begin{equation*}
            A \lor B,
        \end{equation*}
        then you can chose whichever you prefer, you can prove \( A \), or you can prove \( B \), you chose. Proving \( A \), proves \( A \lor B \), and proving \( B \) also proves \( A \lor B \) (look at the truth table). However, in practice, it is not that simple, because \( A \) and \( B \) can both depend on the same parameter, where for some of its value \( A \) is true while \( B \) is false, and for the rest of the values, \( B \) is true while \( A \) is false. In that case (which is honestly the most frequent one), the trick is to do the following. We want to prove \( A \lor B \). Suppose \( A \) is true, then great, we proved \( A \lor B \), if not, then that means that \( A \) is false, and let us prove \( B \). This works nicely, because now to prove \( B \), we have a new hypothesis in our pocket, namely, that \( A \) is false. Let us see an example.
        \begin{equation*}
            \forall n \in \bb N, n \text{ is even, or } n \text{ is odd}.
        \end{equation*}
        \begin{proof}
            Let \( n \in \bb N \) (let us not forget the previous point!!). Then we see that we will not be able to prove that \( n \) is even, or \( n \) is odd, because we do not have enough information on \( n \). Therefore, we do the trick. Suppose \( n \) is not even, then (this is the definition of odd), \( n \) is odd.
        \end{proof}
        
    \item If you need to prove a statement of the form
        \begin{equation*}
            \exists x \in X, P(x),
        \end{equation*}
        then there is no general method. The only way is that you, mathematician, work and construct an \( x \) in \( X \) making \( P(x) \) true. You will have to bring to existence a particular element of the set that satisfies the property \( P \). In general, not all elements of \( X \) satisfy \( P \), the statement \( \exists x \in X, P(x) \) says that there exists at least one in \( X \) that does, and the role of the proof is to find it. For instance,
        \begin{equation*}
            \exists n \in \bb N, n + 7 = 9.
        \end{equation*}
        \begin{proof}
            By taking \( n = 2 \), we see that \( 2 + 7 = 9 \).
        \end{proof}

    \item There is a common upgrade to the exists quantifier. We write \( \exists! \) to mean \cemph{there exists a unique}. To prove that there exists a unique, the standard way to prove that is to decompose the proof in two steps. First, we prove that there indeed exists something, and then, we assume that we have another thing, and prove that in fact it has to be the one we just exhibited from the existence. For instance,
    \begin{equation*}
        \exists! n \in \bb N, n + 7 = 9.
    \end{equation*}
    \begin{proof}
        We already saw that \( n = 2 \) proves the existence. Suppose we have an \( m \in \bb N \) such that \( m + 7 = 9 \), then \( m = 9 - 7 = 2 \), proving the uniqueness.
    \end{proof}

    \item However, sometimes it is useful to prove that something is unique, \textit{without proving it exists}. The way to do is to assume that we have two such things \( a, b \), and then prove that \( a = b \).
    
    \item If you want to prove a statement of the form
    \begin{equation*}
        A \implies B,
    \end{equation*}
    then you \cemph{your proof will always begin by "assume \( A \)"}. \cemph{You put the hypothesis \( A \) in your bag of hypothesis}, and you use it to move towards \( B \). Maybe you will not use \( A \) right away, but remember when you are stuck that there is this \( A \) lying around! For instance,
    \begin{equation*}
        \forall n \in \bb N \left((n \text{ is even}) \implies (n \mod 4) \in \{ 0, 2 \} \right).
    \end{equation*}
    \begin{proof}
        Let \( n \in \bb N \), and assume \( n \) is even. We do the euclidean division of \( n \) by \( 4 \), we have \( n = 4q + r \) with \( 0 \le r < 4 \). By definition \( (n \mod 4) \) is the reminder \( r \), so we want to prove that \( r = 0 \) or \( r = 1 \). \cemph{By hypothesis, \( n \) is even}, so \( n = 2k \) for some integer \( k \), therefore we have \( 2k = 4q + r \). Reordering this expression, we obtain \( r = 2(k-2q) \), thus \( r \) is even, and \( 0 \le r < 4 \), hence \( r = 0 \) or \( r = 2 \).
    \end{proof}
    Notice also in this proof how the application of the theorem of euclidean division added another hypothesis in our bag, namely that \( 0 \le r < 4 \), that we later used to proved that \( r = 0 \) or \( r = 2 \).

    \item There is another equivalent way to prove the statement \( A \implies B \), it is to prove \( \neg B \implies \neg A \). Sometimes it is easier to work with this way. We call it the \cemph{contrapositive}.
    \item Beware that we said \( A \implies B \) is the same thing as \( \neg B \implies \neg A \), and that we did NOT say something else, that people wrongly do instead. 
    \item If you want to prove \( A \iff B \), then you prove first \( A \implies B \), and second \( B \implies A \). Of course, using contrapositive, you can also first prove \( A \implies B \), then \( \neg A \implies \neg B \).
    
    \item If you need to prove a statement of the form 
    \begin{equation*}
        \neg A,
    \end{equation*}
    then the standard way is to assume that \( A \) is true, so putting it in our bag of hypothesis, and then deduce a contradiction. For instance,
    \begin{equation*}
        \neg(3 \text{ is even})
    \end{equation*}
    \begin{proof}
        Suppose \( 3 \) is even, then \( 3 = 2k \) for some integer \( k \), but solving for \( k \), we get \( k = \frac 3 2 \), which is not an integer, contradiction. 
    \end{proof}
    We see here that the contradiction we reached was provided by "\( k \) is an integer", and "\( k \) is not an integer". A lot of contradictions arise this way, whose general form is \( A \land \neg A \). So to prove that there is a contradiction, a common way is to prove that something and the negation of the same thing are both true at the same time. This is why for instance \( 0 = 1 \) is a contradiction. Indeed, we can prove \( \neg (0 = 1) \), so if we also prove \( 0 = 1 \), then this is the general contradiction shape with \( A \equiv "0 = 1" \).
\end{itemize}

Here is some more ways to prove things. 
\begin{cdef}{}{modus_ponens}
    If \( A \) is true, and \( A \implies B \) is true, then \( B \) is true. This principle is valid, and is known as the \cemph{modus ponens}.
\end{cdef} 
This is in fact why we prove theorem. Indeed, this principle means that we can use the theorems we proved in the past. Suppose we proved a very cool theorem, whose statement is given by \( A \), then (as we proved it), \( A \) is true. Suppose now we want to prove some seemingly related statement \( B \), then according to modus ponens, to prove \( B \), it suffices to prove \( A \implies B \). By the above, to prove \( A \implies B \), we assume first that \( A \) is true (we already know it, but why not), and we add it in our bag of hypothesis, then we proceed to prove \( B \). In practice, it means that we can use the theorem \( A \) during the proof of \( B \). This is the deep reason why we can use theorem. For a more formal construction of this, see the \text{cut-elimination} procedure.  

\begin{cdef}{}{induction}
    The \cemph{induction principle} tells us
    \begin{equation*}
        \left(P(0) \land (\forall n \in \bb N, P(n) \implies P(n+1)) \right) \implies \forall n \in \bb N, P(n).
    \end{equation*} 
\end{cdef}
What is this telling us? Suppose we want to prove something of the shape
\begin{equation*}
    \forall n \in \bb N, P(n),
\end{equation*}
Then, if we can prove 
\begin{equation*}
    P(0) \land (\forall n \in \bb N, P(n) \implies P(n+1)),
\end{equation*}
by modus ponens, and the induction principle, it will prove \( \forall n \in \bb N, P(n) \). Now, to prove somehting \( A \land B \), we first do \( A \), then \( B \). In our case, we first prove \( P(0) \), this is the \cemph{base case}. Then we prove \( \forall n \in \bb N, P(n) \implies P(n+1) \), this is the \cemph{inductive step}. According to our rules, to prove something like that, we start the proof by "let \( n \in \bb N \)", and we prove \( P(n) \implies P(n+1) \). According to the rules again, to prove that, we assume \( P(n) \) and need to prove \( P(n + 1) \). In short, the proof of \( \forall n \in \bb N, P(n) \implies P(n+1) \) starts with:
"Let \( n \in \bb N \), and assume \( P(n) \) is true", then we do maths to prove \( P(n+1) \). This is how we already knew induction.

\begin{cex}{}{strong_inductions}
    Use induction to prove the (very useful in practice) strong induction principle:
    \begin{equation*}
        \left(P(0) \land (\forall n \in \bb N, (\forall m \le n, P(m)) \implies P(n+1)) \right) \implies \forall n \in \bb N, P(n).
    \end{equation*} 
\end{cex}
\subsubsection{Destructing proofs}

Now that we saw how to prove something, it is time to do the opposite, and see how to use something we already proved. Indeed, hypothesis in our bag have certain shapes. It is time to see how to use deconstruct those shapes to apply them in our proofs. Thus, we place ourselves in the situation where we are doing a proof, and during this proof (as always) we have a bag of hypothesis.
\begin{itemize}
    \item Suppose we have an hypothesis \( A \land B \) in the bag. Then at any time during the proof, we can use \( A \) and we can use \( B \). It thus means that having \( A \land B \) in our bag of hypothesis is the same thing as having \( A \), and also having \( B \). 
    \item Suppose we have an hypothesis \( A \lor B \) in the bag. Then if we want to use this hypothesis, we need to do two times the proof. One using assuming that \( A \) is true, and another assuming that \( B \) is true. Indeed, when we have \( A \lor B \), we do not know what the universe will give us \( A \) or \( B \)? Hence, we take care, and make sure everything will be ok whatever she gives us.
    \item Suppose we have an hypothesis \( A \implies B \) in our bag, then if we can find some \( A \) in the bag, we get a \( B \) for free!  
    \item Suppose we have an hypothesis \( \forall x \in X, P(x) \) in our bag. Then whenever we have an element \( x \in X \), we know for free that \( P(x) \). For instance, let us prove \( \neg (\forall n \in \bb N, n\text{ is even}) \).
    \begin{proof}
        Suppose \( \forall n \in \bb N, n\text{ is even} \), then \( "\forall n \in \bb N, n\text{ is even}" \) is in our bag of hypothesis. Thus using it with \( n = 1 \), we obtain \( 1 \) is even. Contradiction.
    \end{proof}
    \item Suppose we have an hypothesis \( \exists x \in X, P(x) \) in our bag. Then, we can deconstruct it into \textit{some} \( x_0 \in X \), and a guarantee that \( P(x_0) \). However, we do \cemph{not} choose which \( x_0 \) we get. The hypothesis gives us some, but does not tell us which one (of the potentially many possible) it is. Therefore, the only interest of \( x_0 \) is that it satisfies \( P \).
    
    \item Suppose we have an hypothesis \( \neg A \) in our bag. Then if we can prove that \( A \) is true, we have a contradiction. 
    
    \item However in practice, we often distribute the negation. Indeed, we have (in classical logic), the following rules:
        \begin{itemize}
            \item \( \neg (P \lor Q) \iff (\neg P \land \neg Q) \),
            \item \( \neg (P \and Q) \iff (\neg P \lor \neg Q) \),
            \item \( \neg (\forall x \in X, P(x)) \iff (\exists x \in X, \neg P(x)) \),
            \item \( \neg (\exists x \in X, P(x)) \iff (\forall x \in X, \neg P(x)) \).
        \end{itemize}
    Using that, we see that we can \textit{push} the negation into the very core of the statement, until we ultimately reach an atomic symbol, often a \( = \), or a \( \in \). For instance, instead of using directly the hypothesis \( \neg (\forall n \bb N, \exists k \in \bb N, n = 2k ) \), we will rather use
    \begin{align*}
        \neg (\forall n \bb N, \exists k \in \bb N, n = 2k ) &\iff \exists n \in \bb N, \neg(\exists k \in \bb N, n = 2k ) \\
        &\iff \exists n \in \bb N, \forall k \in \bb N, \neg (n = 2k) \\
        &\iff \exists n \in \bb N, \forall k \in \bb N, n \neq 2k,
    \end{align*}
    meaning that we have a \( n_0 \in \bb N \), such that for each \( k \in \bb N \), \( n_0 \) is not equal to \( 2k \), that is \( n_0 \) is not 0, nor 2, nor 4, nor 6, nor ... i.e. this just claims that there exists an odd number. 
\end{itemize}

\subsubsection{On some of the notations}

As in any language, maths as its own abbreviation, and tacit rules. In the following list, we try to hint some of the ways wa can craft mathematical sentences, what are their implicit assumptions, and how to deal with them.
\begin{itemize}
    \item In most textbook, you will barely see the connective \( \implies \), and somehow it is the one that is the most widely used. This is because the implication are all implicit, and this is the reader who needs to reconstruct them. For instance, when we write
    \begin{equation*}
        \text{If } P, \text{ then }Q,
    \end{equation*}
    or when we write
    \begin{equation*}
        \text{Suppose } P, \text{ then }Q,
    \end{equation*}
    or when we write
    \begin{equation*}
        \text{Assume } P, \text{ then }Q,
    \end{equation*}
    then we really mean \( P \implies Q \), this is just a way to write it in english. Therefore, when you will have to prove a statement "if \( P \), then \( Q \)", you will have to use the techniques described for the \( \implies \) connective.

    \item The forall quantifier is also very often implicit, or written in plain english. For instance, we will write "check that for all \( x \) in \( X \), \( P(x) \)". Worse, it is also very common to say "prove that if \( x \in X \), then \( P(x) \). This sentence translate formally as "\( \forall x \in X, P(x) \)". Therefore, we use the "if ... then ..." construction to really mean a forall. This means no harm, as forall is secretly a generalization of the implication. Maybe you will feel that once you get use to math enough. 
    
    \item The exists \( \exists \) quantifier also read as "there is", "for some", etc.
    
    \item When dealing with quantifiers, we also often say "such that". For instance \( \exists y \in X, \forall x \in X, x = y \) would read as \textit{there is some \( y \) in \( X \) \cemph{such that} for all \( x \) in \( X \), \( x = y \)}. Exercise: convince yourself that this in in fact the definition of \( \exists! x \in X \). 
    
    \item When we say "it suffices that \( A \) for \( B \)", it means that \( A \implies B \). For instance, it suffices that \( n \) is divisible by \( 4 \) to be even. When we say "it is necessary that \( A \) for \( B \)", it means that \( B \implies A \). For instance, it is necessary that \( n \) is even for \( n \) to be divisible by \( 4 \). If we say "\( A \) is sufficient and necessary for \( B \)", then it means \( A \iff B \).
    
    \item When we write "i.e.", we mean that what comes before is the same thing as what come after. For instance in a proof, we will find "\( n + 1 = m \), i.e. \( 'n = m - 1 \)". We also use "that is" in place of "i.e." (in fact, i.e. is "id est" in Latin, which translates to "that is").
    
    \item In these notes, we use the notation \( \defeq \) to define a new object, like an abbreviation for the new thing. Thus, when we write \( a = b \), it means that the thing \( a \) we are already working with is equal to the thing \( b \) we were already working with, but when we write \( a \defeq b \), we are giving a new name to the thing \( b \). Of course, after writing \( a \defeq b \), we also have \( a = b \). This notation might seem useless, but is often convenient to remember that we are not claiming any mathematical truth, just a way to abbreviate something longer.
     
    \item This is not purely notational, but it is very useful to typecheck! If you are a physicist, then you know it already (we do not add meters with kilograms). If you program in a typed language then you know it already (a variable of type \verb|int| cannot be a variable of type \verb|string|). Math is a typed language. If something does not typecheck, then it is either an abuse of notation (try to make the notation more explicit if you are not familiar with it enough), or an error.
\end{itemize}

Unfortunately, this list is far from being exhaustive. Worse, each subfield of math uses its own abbreviation, notation, and way of saying things. Mathematic is a language that contains many many subvarieties, and it is often difficult, when learning a new subject, to familiarize oneself with its sometimes peculiar rules. Notice however that no domain of math says something false. That is, everything will \cemph{always} have a precise and well defined meaning. It might juts take some time and effort to see it. Once you are use to it, you understand the power of notation, and the great things you can do with it. 
